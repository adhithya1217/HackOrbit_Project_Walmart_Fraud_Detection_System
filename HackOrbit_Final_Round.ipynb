import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
import joblib

from google.colab import files
uploaded = files.upload()

print(df['IsFraud'].value_counts(normalize=True))
sns.countplot(x='IsFraud', data=df);


X = df.drop('IsFraud', axis=1)
y = df['IsFraud']

categorical_cols = X.select_dtypes(include=['object']).columns

X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

joblib.dump(rf, 'balanced_rf_model.joblib')

y_pred = rf.predict(X_test)
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

y_proba = rf.predict_proba(X_test)[:, 1]
threshold = 0.2
y_pred_thresh = (y_proba >= threshold).astype(int)

print(confusion_matrix(y_test, y_pred_thresh))
print(classification_report(y_test, y_pred_thresh))

print("Type of rf:", type(rf))

print("Type of X_test:", type(X_test))

print(hasattr(rf, "predict_proba"))

explainer = shap.TreeExplainer(rf)
shap_values = explainer.shap_values(X_test)

print("shap_values[1] shape:", shap_values[1].shape)
print("X_test shape:", X_test.shape)
print("X_train shape:", X_train.shape)
print("X_train columns:", list(X_train.columns))
print("X_test columns:", list(X_test.columns))

from sklearn.ensemble import RandomForestClassifier
import shap
import pandas as pd

# Refit model to ensure correctness
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

print("Type of rf:", type(rf))

X_test_reordered = X_test[X_train.columns]

print("X_test_reordered shape:", X_test_reordered.shape)
print("X_train shape:", X_train.shape)

explainer = shap.TreeExplainer(rf)

X_small = X_test_reordered.iloc[:10]

shap_values = explainer.shap_values(X_small)
print("shap_values[0] shape:", shap_values[0].shape)
print("shap_values[1] shape:", shap_values[1].shape)

# checking all class seen by the model:
print("Classes seen by model:", rf.classes_)

shap_values = explainer.shap_values(X_small)
shap.summary_plot(shap_values, X_small)

pip install streamlit

import streamlit as st
import pandas as pd
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np # Import numpy

st.set_page_config(layout="wide") # Use wide layout

st.title('Walmart Fraud Detection App')
st.write('Analyze transaction data and predict fraud using a trained model.')

# Load data and model
@st.cache_resource # Cache the data loading
def load_data(file_path):
    try:
        df = pd.read_csv(file_path)
        return df
    except FileNotFoundError:
        st.error(f"Error: File not found at {file_path}")
        return None
    except Exception as e:
        st.error(f"Error loading data: {e}")
        return None

@st.cache_resource # Cache the model loading
def load_model(file_path):
    try:
        model = joblib.load(file_path)
        return model
    except FileNotFoundError:
        st.error(f"Error: Model file not found at {file_path}")
        return None
    except Exception as e:
        st.error(f"Error loading model: {e}")
        return None

df = load_data('synthetic_augmented_transactions.csv')
model = load_model('balanced_rf_model.joblib')

if df is None or model is None:
    st.stop() # Stop the app if data or model failed to load


# Upload New Data
st.sidebar.header("Upload Your Data")
uploaded_file = st.sidebar.file_uploader("Upload a CSV file", type=["csv"])


